{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f54b0a1",
   "metadata": {},
   "source": [
    "# ‚ö†Ô∏è IMPORTANT\n",
    "\n",
    "**Please Read the README.MD before running this notebook**\n",
    "README.MD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from src.data_gen_pipelines import CharGenBatchJob, CharEnvBatchJob, ConversationBatchJob, RawBatchJob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db83a77",
   "metadata": {},
   "source": [
    "# Init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3970d16",
   "metadata": {},
   "source": [
    "# Generate Character-Environment-Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e32e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ Run only once!\n",
    "# char_gen_job = CharGenBatchJob(OPENAI_API_KEY,\"data/temp/char_names.csv\", \"data/temp/char.csv\", \"data/prompt/char_gen.md\")\n",
    "# char_gen_job.invoke_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0342b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ Run whenever Ever after Restart! does not effect the code\n",
    "# char_gen_job = CharGenBatchJob(OPENAI_API_KEY,\"data/temp/char_names.csv\", \"data/temp/char.csv\", \"data/prompt/char_gen.md\")\n",
    "# char_gen_job.job_id = \"Run it Above first then paste **THEN PASTE GENERATED JOB ID HERE**\"\n",
    "# char_gen_job.invoke_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b29f84",
   "metadata": {},
   "source": [
    "# Generate Multiple Character-Environment-Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75322d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ Run only once!\n",
    "# char_envs_job = CharEnvBatchJob(OPENAI_API_KEY,\"data/temp/char.csv\", \"data/temp/char_envs.csv\", \"data/prompt/char_envs_gen.md\")\n",
    "# char_envs_job.invoke_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908c92f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ Run whenever Ever after Restart! does not effect the code\n",
    "# char_envs_job = CharEnvBatchJob(OPENAI_API_KEY,\"data/temp/char.csv\", \"data/temp/char_envs.csv\", \"data/prompt/char_envs_gen.md\")\n",
    "# char_envs_job.job_id = \"Run it Above first then paste **THEN PASTE GENERATED JOB ID HERE**\"\n",
    "# char_envs_job.invoke_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95d735",
   "metadata": {},
   "source": [
    "- Here‚Äôs a reusable function that takes any DataFrame and:\n",
    "- Saves the full DF to temp/char_envs.csv (configurable)\n",
    "- Splits it into chunks of at most 7 000 rows (configurable)\n",
    "- Writes each chunk to temp/char_envs/char_envs_part<N>.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d482eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_split_df(\n",
    "    df: pd.DataFrame,\n",
    "    out_dir: str = \"data/temp\",\n",
    "    filename: str = \"char_envs.csv\",\n",
    "    subfolder: str = \"char_envs\",\n",
    "    chunk_size: int = 7000\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Saves the full DataFrame and splits it into smaller CSV chunks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to save and split.\n",
    "    out_dir : str, default \"temp\"\n",
    "        Base directory where files will be written.\n",
    "    filename : str, default \"char_envs.csv\"\n",
    "        Name of the full-DataFrame CSV.\n",
    "    subfolder : str, default \"char_envs\"\n",
    "        Subdirectory under out_dir for chunked files.\n",
    "    chunk_size : int, default 7000\n",
    "        Maximum number of rows per chunk.\n",
    "\n",
    "    Writes\n",
    "    ------\n",
    "    - {out_dir}/{filename}\n",
    "    - {out_dir}/{subfolder}/char_envs_part1.csv\n",
    "    - {out_dir}/{subfolder}/char_envs_part2.csv\n",
    "    - ...\n",
    "    \"\"\"\n",
    "    # ensure directories exist\n",
    "    full_dir = os.path.join(out_dir)\n",
    "    chunks_dir = os.path.join(out_dir, subfolder)\n",
    "    os.makedirs(full_dir, exist_ok=True)\n",
    "    os.makedirs(chunks_dir, exist_ok=True)\n",
    "\n",
    "    # save the complete DataFrame\n",
    "    full_path = os.path.join(full_dir, filename)\n",
    "    df.to_csv(full_path, index=False)\n",
    "    print(f\"Saved full DataFrame ({len(df)} rows) to {full_path}\")\n",
    "\n",
    "    # split into chunks\n",
    "    num_rows = len(df)\n",
    "    for start in range(0, num_rows, chunk_size):\n",
    "        chunk = df.iloc[start : start + chunk_size]\n",
    "        part_num = (start // chunk_size) + 1\n",
    "        part_name = f\"{os.path.splitext(filename)[0]}_part{part_num}.csv\"\n",
    "        part_path = os.path.join(chunks_dir, part_name)\n",
    "        chunk.to_csv(part_path, index=False)\n",
    "        print(f\"  ‚Ä¢ Chunk {part_num}: {len(chunk)} rows ‚Üí {part_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ Run only once!\n",
    "# save_and_split_df(pd.read_csv(\"data/temp/char_envs.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82afd7e",
   "metadata": {},
   "source": [
    "# Generate Conversations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_all_jobs(folder_path: str = \"data/temp/char_envs\") -> list[str]:\n",
    "    \"\"\"\n",
    "    Lists all .csv files in the specified folder (non-recursive).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder_path : str\n",
    "        Path to the directory to scan.\n",
    "    \"\"\"\n",
    "    job_ids = []\n",
    "    try:\n",
    "        for idx, fname in enumerate(os.listdir(folder_path)):\n",
    "            if fname.lower().endswith('.csv'):\n",
    "                char_conv_job = ConversationBatchJob(OPENAI_API_KEY,f\"data/temp/char_envs/char_envs_part{idx}.csv\", \"data/conversation.csv\", \"data/prompt/conversation_gen.md\")\n",
    "                job_ids.append(char_conv_job.invoke_job())\n",
    "        return job_ids\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: {folder_path}\")\n",
    "    \n",
    "    return []\n",
    "\n",
    "def check_and_download(job_ids:list[str],folder_path: str = \"data/temp/char_envs\"):\n",
    "    \"\"\"\n",
    "    Check Each Chunk in job for each csv subfolder and download.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        idx = 0\n",
    "        for fname in os.listdir(folder_path):\n",
    "            if fname.lower().endswith('.csv'):\n",
    "                char_conv_job = ConversationBatchJob(OPENAI_API_KEY,f\"data/temp/char_envs/char_envs_part{idx}.csv\", \"data/conversation.csv\", \"data/prompt/conversation_gen.md\")\n",
    "                char_conv_job.job_id = job_ids[idx]\n",
    "                char_conv_job.invoke_job()\n",
    "                idx = idx + 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552fe6d",
   "metadata": {},
   "source": [
    "**RUN only ONCE!!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d573b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ Run only once!\n",
    "# all_job_ids = start_all_jobs()\n",
    "# print(\"save them in order\",all_job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ Run whenever Ever after Restart! does not effect the code\n",
    "# Check job status and download results when ready (can be run in a loop or manually)\n",
    "# check_and_download(all_job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc03759",
   "metadata": {},
   "source": [
    "# RawDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7703c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ Run only once!\n",
    "# raw_job = RawBatchJob(OPENAI_API_KEY,\"data/raw_df/raw_conv.csv\", \"data/conversations.csv\", \"data/prompt/conv_expand.md\")\n",
    "# raw_job.invoke_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ Run whenever Ever after Restart! does not effect the code\n",
    "# raw_job = RawBatchJob(OPENAI_API_KEY,\"data/raw_df/raw_conv.csv\", \"data/conversations.csv\", \"data/prompt/conv_expand.md\")\n",
    "# raw_job.job_id = \"Run it first commented **THEN PASTE GENERATED JOB ID HERE**\"\n",
    "# raw_job.invoke_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c344ea",
   "metadata": {},
   "source": [
    "# Check ALL the Batch Jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = client.batches.list()\n",
    "len(jobs.data)\n",
    "jobs.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b914fd",
   "metadata": {},
   "source": [
    "# Testing (SKIP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4542364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# import language_tool_python\n",
    "\n",
    "# def correct_grammar(text:str) -> str:\n",
    "#     text = text.replace(\" ,\", \",\").replace(\" .\", \".\").replace(\" ?\", \"?\").replace(\" !\", \"!\")     \n",
    "#     return tool.correct(text)\n",
    "\n",
    "\n",
    "# def convert_dialogues(df:pd.DataFrame):\n",
    "#     output_list = []\n",
    "    \n",
    "#     for _ , row in df.iterrows():\n",
    "#         dialogue = [] \n",
    "#         turn = False\n",
    "#         dialogue.append({\"role\": \"system\", \"content\": correct_grammar(row['Persona'])})\n",
    "#         cg = correct_grammar(row['chat'])\n",
    "#         chat_list = cg.split(\"\\n\")\n",
    "\n",
    "#         for chat_item in chat_list:\n",
    "#             turn = not turn \n",
    "#             if turn and chat_item !=  \"\":\n",
    "#                 dialogue.append({\"role\": \"user\", \"content\": chat_item})\n",
    "#             elif not turn and chat_item != \"\":\n",
    "#                 dialogue.append({\"role\": \"assistant\", \"content\": chat_item})\n",
    "                \n",
    "#         output_list.append(json.dumps({\"conversation\": dialogue}, indent=4))\n",
    "    \n",
    "\n",
    "#     return output_list\n",
    "\n",
    "\n",
    "# # Single shared Tool instance for all threads\n",
    "\n",
    "\n",
    "# tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# def preprocess_text_series(series: pd.Series) -> pd.Series:\n",
    "#     return (series\n",
    "#         .str.replace(r\"\\s+,\", \",\", regex=True)\n",
    "#         .str.replace(r\"\\s+\\.\", \".\", regex=True)\n",
    "#         .str.replace(r\"\\s+\\?\", \"?\", regex=True)\n",
    "#         .str.replace(r\"\\s+!\", \"!\", regex=True)\n",
    "#     )\n",
    "\n",
    "# def _process_row(persona: str, chat: str) -> str:\n",
    "#     sys_text  = tool.correct(persona)\n",
    "#     chat_text = tool.correct(chat)\n",
    "\n",
    "#     dialogue = [{\"role\": \"system\", \"content\": sys_text}]\n",
    "#     turn = True\n",
    "#     for line in chat_text.splitlines():\n",
    "#         if not line.strip():\n",
    "#             continue\n",
    "#         role = \"user\" if turn else \"assistant\"\n",
    "#         dialogue.append({\"role\": role, \"content\": line})\n",
    "#         turn = not turn\n",
    "    \n",
    "#     return json.dumps({\"conversation\": dialogue}, indent=4)\n",
    "\n",
    "# def convert_dialogues_parallel(df: pd.DataFrame, max_workers: int = 16):\n",
    "#     # 1) cleanup\n",
    "#     df = df.copy()\n",
    "#     df['Persona_clean'] = preprocess_text_series(df['Persona'])\n",
    "#     df['Chat_clean']   = preprocess_text_series(df['chat'])\n",
    "\n",
    "#     results = [None] * len(df)\n",
    "#     with ThreadPoolExecutor(max_workers=max_workers) as pool:\n",
    "#         futures = {\n",
    "#             pool.submit(_process_row, persona, chat): idx\n",
    "#             for idx, (persona, chat) in enumerate(\n",
    "#                 zip(df['Persona_clean'], df['Chat_clean'])\n",
    "#             )\n",
    "#         }\n",
    "#         for fut in as_completed(futures):\n",
    "#             idx = futures[fut]\n",
    "#             results[idx] = fut.result()\n",
    "#     tool.close()\n",
    "#     return results\n",
    "\n",
    "\n",
    "# out = convert_dialogues_parallel(df)\n",
    "# new_df = pd.DataFrame({\"conversation\": out})\n",
    "# dff = pd.read_csv(\"conversations.csv\")\n",
    "# pd.concat([dff, new_df], axis=0).to_csv(\"conversation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
